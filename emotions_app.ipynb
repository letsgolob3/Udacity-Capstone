{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\dash_bootstrap_components\\_table.py:5: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\E082499\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\E082499\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\E082499\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import base64\n",
    "import re\n",
    "import pickle\n",
    "import dash\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "from dash.exceptions import PreventUpdate\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash import dash_table\n",
    "from dash.dependencies import Output\n",
    "from dash.dependencies import Input\n",
    "from plotly.subplots import make_subplots\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from emotions_model import count_tokens\n",
    "from emotions_model import apply_features\n",
    "from emotions_model import count_n_char\n",
    "from emotions_model import load_model\n",
    "from emotions_model import tokenize_and_join\n",
    "from emotions_model import get_top_words_per_emotion_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images and Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['surprise', 'love', 'anger', 'sadness', 'fear', 'joy'])\n"
     ]
    }
   ],
   "source": [
    "# Relative paths\n",
    "cwd=os.getcwd()\n",
    "\n",
    "fpath='.\\images\\initial.jpg'\n",
    "\n",
    "test_base64 = base64.b64encode(open(fpath, 'rb').read()).decode('ascii')\n",
    "\n",
    "\n",
    "# Deserializing model object and keywords for indicators\n",
    "pipeML= load_model('model.pkl')\n",
    "\n",
    "handler = open('top_words_per_target.pkl', \"rb\")\n",
    "top_words_per_target= pickle.load(handler)\n",
    "\n",
    "print(top_words_per_target.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App layout and controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app=dash.Dash(__name__,external_stylesheets=[dbc.themes.SPACELAB,\n",
    "                                             \"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\"])\n",
    "\n",
    "\n",
    "\n",
    "app.layout=html.Div([\n",
    "    \n",
    "#Colors and app title\n",
    "    dbc.Row([dbc.Col(\n",
    "                    html.H1('Anger',style={\"color\":\"black\",\"background-color\":\"#F13027\",\n",
    "                                          \"text-align\":\"center\"})\n",
    "                    ,width={'size':2,'offset':0,'order':1}\n",
    "                    ),\n",
    "            dbc.Col(\n",
    "                    html.H1(\"Love\",style={\"color\":\"black\",\"background-color\":\"#F127A1\",\n",
    "                                          \"text-align\":\"center\"})\n",
    "                    ,width={'size':2,'order':2}\n",
    "                    ),\n",
    "            dbc.Col(\n",
    "                    html.H1(\"Joy\",style={\"color\":\"black\",\"background-color\":\"#FFF633\",\n",
    "                                        \"text-align\":\"center\"})\n",
    "                    ,width={'size':2,'order':3}\n",
    "                    ), \n",
    "            dbc.Col(\n",
    "                    html.H1(\"Surprise\",style={\"color\":\"black\",\"background-color\":\"#27F143\",\n",
    "                                             \"text-align\":\"center\"})\n",
    "                    ,width={'size':2,'order':4}\n",
    "                    ), \n",
    "            dbc.Col(\n",
    "                    html.H1(\"Sadness\",style={\"color\":\"black\",\"background-color\":\"#279BF1\",\n",
    "                                            \"text-align\":\"center\"})\n",
    "                    ,width={'size':2,'order':5}\n",
    "                    ), \n",
    "            dbc.Col(\n",
    "                    html.H1(\"Fear\",style={\"color\":\"black\",\"background-color\":\"#9827F1\",\n",
    "                                         \"text-align\":\"center\"})\n",
    "                    ,width={'size':2,'order':6}\n",
    "                    ), \n",
    "            ]),\n",
    "\n",
    "    \n",
    "#Free text input for user text.  The dcc store is used to store data in browser and\n",
    "    #can share data between callbacks \n",
    "    dbc.Row([dbc.Col([\n",
    "                    html.Div([\"How are you feeling\"],style={'font-size':24}),\n",
    "                    dcc.Input(id='text_input',placeholder='Enter text..',type='text',style={'font-size':24,\n",
    "                                                                                      'width':'80%'})],\n",
    "            width={'size':6,'offset':1}),\n",
    "            ]),\n",
    "    \n",
    "    dcc.Download(id='download_excel'),    \n",
    "    dcc.Store(id='saved_data',data={}),\n",
    "    dcc.Store(id='df_filtered',data={}),\n",
    "\n",
    "# Variable image\n",
    "    dbc.Row([\n",
    "\n",
    "        dbc.Col([\n",
    "                html.Br(),\n",
    "                html.Img(id='picture',src='data:image/png;base64,{}'.format(test_base64)),\n",
    "\n",
    "                ],\n",
    "                width={'offset':5,'order':1},\n",
    "\n",
    "                ),#End dbc.Col\n",
    "        \n",
    "            ]), #End dbc.Row\n",
    "        \n",
    "\n",
    "    dbc.Row([html.Br()]),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Graph(id='sentiment')],width={'size':4,'offset':4}),\n",
    "        ]), #End dbc.Row\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Table([\n",
    "                html.Tr([html.Td(['Sentiment Subjectivity:  '],\n",
    "                                 style={'font-size':24}), \n",
    "                         html.Td(id='subj',\n",
    "                                 style={'text-align':'right','font-size':24})],\n",
    "                         style={'text-align':'right','font-size':24}),\n",
    "                html.Tr([html.Td('The subjectivity is in the range [0.0, 1.0]',\n",
    "                                  style={'text-align':'right','font-size':16})],\n",
    "                        style={'text-align':'right','font-size':16}),\n",
    "                html.Tr([html.Td('where 0.0 is very objective and 1.0 is very subjective',\n",
    "                                  style={'text-align':'right','font-size':16})],\n",
    "                        style={'text-align':'right','font-size':16}),\n",
    "                        ]), # End Table \n",
    "                ],width={'offset':5}) # End Col\n",
    "\n",
    "    ]) #End Row\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "                    \n",
    "]) #End html.Div\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Populate the graph with sentiment and subjectivity\n",
    "# 2) Populate the image based on the value of model output \n",
    "\n",
    "@app.callback(\n",
    "    Output(component_id='sentiment',component_property='figure'),\n",
    "    Output('picture', 'src'),\n",
    "    Output('subj','children'),\n",
    "    Input(component_id='text_input',component_property='value')\n",
    "\n",
    ")\n",
    "\n",
    "def set_graph(text):\n",
    "    \n",
    "    print(text)\n",
    "    '''\n",
    "    INPUT\n",
    "    text - a string of text based on the user input in the application\n",
    "\n",
    "    OUTPUT\n",
    "    fig - a figure to show the sentiment and subjectivity of the text using the TextBlob library\n",
    "    '''    \n",
    "    \n",
    "    \n",
    "    def SetColor(y):\n",
    "        '''\n",
    "        INPUT\n",
    "        y - the y-value for the graph\n",
    "\n",
    "        OUTPUT\n",
    "        col - color based on y-value\n",
    "        '''            \n",
    "        if y>=0:\n",
    "            col= \"#3F9C35\"\n",
    "        else:\n",
    "            col= \"red\"\n",
    "        return col\n",
    "\n",
    "    \n",
    "    \n",
    "    if text is None:\n",
    "        raise PreventUpdate\n",
    "    \n",
    "    \n",
    "    #Sentiment from Textblob\n",
    "\n",
    "    tb_phrase = TextBlob(text)\n",
    "    \n",
    "    phrase_corrected=str(tb_phrase.correct())\n",
    "    \n",
    "    \n",
    "    if tb_phrase==phrase_corrected:\n",
    "#         print('No spelling errors')\n",
    "        pass\n",
    "    else:\n",
    "#         print('Spelling error! Fixed')\n",
    "#         print(phrase_corrected)\n",
    "        tb_phrase=TextBlob(phrase_corrected)\n",
    "    \n",
    "\n",
    "    sentiment=tb_phrase.sentiment\n",
    "\n",
    "    polarity=sentiment.polarity\n",
    "\n",
    "    subjectivity=sentiment.subjectivity\n",
    "\n",
    "    #Variables for graph\n",
    "    x=['Sentiment']\n",
    "\n",
    "    ydf=pd.DataFrame([polarity],columns=[\"y1\"])\n",
    "\n",
    "    if polarity<0:\n",
    "\n",
    "        y_text = ['Negative']\n",
    "    else:\n",
    "        y_text = ['Positive']\n",
    "\n",
    "\n",
    "    #Graph properties\n",
    "    fig = go.Figure(data=go.Bar(x=x, y=ydf['y1'],text=y_text,\n",
    "                                marker=dict(color = list(map(SetColor, ydf[\"y1\"])))))\n",
    "\n",
    "    fig.update_traces(marker_line_color='black',marker_line_width=1.5,opacity=0.6)\n",
    "\n",
    "\n",
    "    fig.update_layout(title_text=\"Sentiment score: -1 to 1\",\n",
    "                      title_font_size=30,\n",
    "                      font=dict(size=24),\n",
    "                      title_x=0.5)\n",
    "\n",
    "    fig.update_yaxes(range=[-1,1],tickvals=[-1, -0.5, 0, 0.5,1],\n",
    "                     zeroline=True,zerolinewidth=2,\n",
    "                     zerolinecolor='black',showgrid=True)  \n",
    "    \n",
    "    #Instantiate feature generation object and use methods for preprocessing\n",
    "\n",
    "    new_text_df=pd.DataFrame({'document':[text]},columns=['document'])\n",
    "    \n",
    "    new_text_df['document']=new_text_df['document'].apply(tokenize_and_join)\n",
    "       \n",
    "    new_text_df=apply_features(new_text_df)\n",
    "    \n",
    "    # Adding in the indicators as features\n",
    "    for emotion in top_words_per_target.keys():\n",
    "        new_text_df[f'has_top_{emotion}_word']=new_text_df['document'].str.contains('|'.join(top_words_per_target[emotion]))\n",
    "    \n",
    "    \n",
    "    [new_text_df[f'has_top_{emotion}_word'].replace({True:1,False:0},inplace=True) \\\n",
    "         for emotion in top_words_per_target.keys()]\n",
    "    \n",
    "    \n",
    "    print(new_text_df.head())\n",
    "    \n",
    "    # Use trained model on new text and output result via image\n",
    "\n",
    "    pred=pipeML.predict(new_text_df)\n",
    "    \n",
    "    pred_emotion=list(pred)[0]\n",
    "    \n",
    "    \n",
    "    fpath=f\".\\images\\{pred_emotion}.jpg\"\n",
    "    \n",
    "    test_base64 = base64.b64encode(open(fpath, 'rb').read()).decode('ascii')\n",
    "    src='data:image/png;base64,{}'.format(test_base64)\n",
    "    \n",
    "    return fig,src,round(subjectivity,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [26/May/2022 15:38:02] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:02] \"\u001b[37mGET /_dash-component-suites/dash/deps/react@16.v2_0_0m1632235559.14.0.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:02] \"\u001b[37mGET /_dash-component-suites/dash/deps/react-dom@16.v2_0_0m1632235559.14.0.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:02] \"\u001b[37mGET /_dash-component-suites/dash/deps/polyfill@7.v2_0_0m1632235559.12.1.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:02] \"\u001b[37mGET /_dash-component-suites/dash_bootstrap_components/_components/dash_bootstrap_components.v0_13_0m1627744119.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:02] \"\u001b[37mGET /_dash-component-suites/dash/deps/prop-types@15.v2_0_0m1632235559.7.2.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:02] \"\u001b[37mGET /_dash-component-suites/dash/dash-renderer/build/dash_renderer.v2_0_0m1632235559.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:02] \"\u001b[37mGET /_dash-component-suites/dash/dcc/dash_core_components.v2_0_0m1632235559.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:02] \"\u001b[37mGET /_dash-component-suites/dash/dcc/dash_core_components-shared.v2_0_0m1632235559.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:02] \"\u001b[37mGET /_dash-component-suites/dash/html/dash_html_components.v2_0_0m1632235559.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:03] \"\u001b[37mGET /_dash-component-suites/dash/dash_table/bundle.v5_0_0m1632235559.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:03] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:03] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:03] \"\u001b[37mGET /_favicon.ico?v=2.0.0 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:03] \"\u001b[37mGET /_dash-component-suites/dash/dcc/async-graph.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:03] \"\u001b[37mGET /_dash-component-suites/dash/dcc/async-plotlyjs.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:03] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 204 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2022 15:38:03] \"\u001b[37mGET /_favicon.ico?v=2.0.0 HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "Bo\n",
      "Bor\n",
      "Bore\n",
      "Bored\n",
      "Bored \n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0     bore         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 1336, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\dash\\_callback.py\", line 151, in add_context\n",
      "    output_value = func(*func_args, **func_kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-4-1493a31363c9>\", line 98, in set_graph\n",
      "    new_text_df['document']=new_text_df['document'].apply(tokenize_and_join)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 4200, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"pandas\\_libs\\lib.pyx\", line 2402, in pandas._libs.lib.map_infer\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 322, in tokenize_and_join\n",
      "    tokens= tokenize(text)\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 296, in tokenize\n",
      "    tokens = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 296, in <listcomp>\n",
      "    tokens = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py\", line 38, in lemmatize\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\", line 120, in __getattr__\n",
      "    self.__load()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\", line 94, in __load\n",
      "    args, kwargs = self.__args, self.__kwargs\n",
      "AttributeError: 'WordNetCorpusReader' object has no attribute '_LazyCorpusLoader__args'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:15] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 1336, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\dash\\_callback.py\", line 151, in add_context\n",
      "    output_value = func(*func_args, **func_kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-4-1493a31363c9>\", line 98, in set_graph\n",
      "    new_text_df['document']=new_text_df['document'].apply(tokenize_and_join)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 4200, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"pandas\\_libs\\lib.pyx\", line 2402, in pandas._libs.lib.map_infer\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 322, in tokenize_and_join\n",
      "    tokens= tokenize(text)\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 296, in tokenize\n",
      "    tokens = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 296, in <listcomp>\n",
      "    tokens = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py\", line 38, in lemmatize\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\", line 120, in __getattr__\n",
      "    self.__load()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\", line 94, in __load\n",
      "    args, kwargs = self.__args, self.__kwargs\n",
      "AttributeError: 'WordNetCorpusReader' object has no attribute '_LazyCorpusLoader__args'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2022 15:38:15] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:15] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 1336, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\dash\\_callback.py\", line 151, in add_context\n",
      "    output_value = func(*func_args, **func_kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-4-1493a31363c9>\", line 98, in set_graph\n",
      "    new_text_df['document']=new_text_df['document'].apply(tokenize_and_join)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 4200, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"pandas\\_libs\\lib.pyx\", line 2402, in pandas._libs.lib.map_infer\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 322, in tokenize_and_join\n",
      "    tokens= tokenize(text)\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 296, in tokenize\n",
      "    tokens = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 296, in <listcomp>\n",
      "    tokens = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py\", line 38, in lemmatize\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\", line 120, in __getattr__\n",
      "    self.__load()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\", line 94, in __load\n",
      "    args, kwargs = self.__args, self.__kwargs\n",
      "AttributeError: 'WordNetCorpusReader' object has no attribute '_LazyCorpusLoader__args'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2022 15:38:15] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 1336, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\dash\\_callback.py\", line 151, in add_context\n",
      "    output_value = func(*func_args, **func_kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-4-1493a31363c9>\", line 98, in set_graph\n",
      "    new_text_df['document']=new_text_df['document'].apply(tokenize_and_join)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 4200, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"pandas\\_libs\\lib.pyx\", line 2402, in pandas._libs.lib.map_infer\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 322, in tokenize_and_join\n",
      "    tokens= tokenize(text)\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 296, in tokenize\n",
      "    tokens = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 296, in <listcomp>\n",
      "    tokens = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py\", line 38, in lemmatize\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\", line 120, in __getattr__\n",
      "    self.__load()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\", line 94, in __load\n",
      "    args, kwargs = self.__args, self.__kwargs\n",
      "AttributeError: 'WordNetCorpusReader' object has no attribute '_LazyCorpusLoader__args'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2022 15:38:15] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 1336, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\dash\\_callback.py\", line 151, in add_context\n",
      "    output_value = func(*func_args, **func_kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-4-1493a31363c9>\", line 98, in set_graph\n",
      "    new_text_df['document']=new_text_df['document'].apply(tokenize_and_join)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 4200, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"pandas\\_libs\\lib.pyx\", line 2402, in pandas._libs.lib.map_infer\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 322, in tokenize_and_join\n",
      "    tokens= tokenize(text)\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 296, in tokenize\n",
      "    tokens = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
      "  File \"C:\\Users\\E082499\\OneDrive - RSM\\python_scripts\\Project 4 Capstone\\Project 4\\emotions_model.py\", line 296, in <listcomp>\n",
      "    tokens = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py\", line 38, in lemmatize\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\", line 120, in __getattr__\n",
      "    self.__load()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\", line 94, in __load\n",
      "    args, kwargs = self.__args, self.__kwargs\n",
      "AttributeError: 'WordNetCorpusReader' object has no attribute '_LazyCorpusLoader__args'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2022 15:38:15] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bored oBored ou\n",
      "\n",
      "Generating features\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "Bored out   document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  bored ou         2    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "\n",
      "Bored out oBored out \n",
      "Bored out of\n",
      "\n",
      "Generating features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:15] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features\n",
      "Generating features\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "Bored out of \n",
      "Generating features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bored out of m\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "Bored out of myBored out of my miBored out of my \n",
      "\n",
      "\n",
      "Bored out of my m\n",
      "Generating featuresGenerating featuresGenerating features\n",
      "\n",
      "\n",
      "Generating features\n",
      "Bored out of my mindBored out of my min\n",
      "   document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  bored my         2    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "\n",
      "   document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  bored my         2    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "   document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  bored my         2    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "      document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  bored my mi         3    0       -0.5                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "Generating features\n",
      "Generating features\n",
      "        document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  bored my mind         3    0       -0.5                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  bored my min         3    0       -0.5                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:43] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bored out of my min\n",
      "Generating features\n",
      "       document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  bored my min         3    0       -0.5                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "Bored out of my mi\n",
      "Generating features\n",
      "Bored out of my m\n",
      "      document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  bored my mi         3    0       -0.5                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "Bored out of my \n",
      "Bored out of my\n",
      "Bored out of m\n",
      "Bored out of "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating features\n",
      "Generating featuresGenerating features\n",
      "\n",
      "Generating featuresGenerating features\n",
      "\n",
      "   document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  bored my         2    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "   document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  bored my         2    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "   document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  bored my         2    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0    document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "\n",
      "Bored out of\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bored out oBored out \n",
      "\n",
      "Bored outBored ou\n",
      "\n",
      "Bored oGenerating features\n",
      "\n",
      "Generating featuresGenerating features\n",
      "Bored \n",
      "\n",
      "Generating features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "\n",
      "Generating features\n",
      "   document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  bored ou         2    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoredBoreBorBo\n",
      "B\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating featuresGenerating features\n",
      "\n",
      "Generating featuresGenerating features\n",
      "\n",
      "Generating featuresGenerating features\n",
      "\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0        b         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0      bor         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0     bore         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0    document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0       bo         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    bored         1    0       -0.5                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n",
      "cacan\n",
      "\n",
      "Generating features\n",
      "Generating featuresGenerating features\n",
      "\n",
      "can'\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0        c         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0       ca         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  can't  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features\n",
      "can't \n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "can't b\n",
      "can't be\n",
      "Generating features\n",
      "Generating features\n",
      "can't bel\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0        b         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0    document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "\n",
      "Generating features\n",
      "can't beli  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0      bel         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:45] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features\n",
      "can't belie\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0     beli         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    belie         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't believ\n",
      "can't believe\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0   believ         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  Generating features\n",
      "\n",
      "can't believe \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  believe         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "Generating features\n",
      "can't believe t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  believe         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "Generating features\n",
      "can't believe th\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  believe         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "can't believe tha\n",
      "Generating features\n",
      "Generating features\n",
      "     document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe th         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "can't believe that"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "can't believe that \n",
      "      document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe tha         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "can't believe that hGenerating features\n",
      "\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  believe         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  can't believe that ha"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:47] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:47] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  believe         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "\n",
      "Generating features\n",
      "Generating features\n",
      "can't believe that hap    document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe h         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "\n",
      "     document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe ha         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  Generating features\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:47] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:47] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:47] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't believe that happ\n",
      "can't believe that happe\n",
      "      document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe hap         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "can't believe that happenGenerating features\n",
      "\n",
      "Generating features\n",
      "       document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe happ         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "Generating features\n",
      "can't believe that happene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:47] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:47] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:47] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:47] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe happe         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0           document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe happen         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "\n",
      "Generating features\n",
      "          document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe happene         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "can't believe that happened\n",
      "Generating features\n",
      "           document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe happened         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:47] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:49] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't believe that happene\n",
      "Generating features\n",
      "          document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe happene         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "can't believe that happen\n",
      "can't believe that happe\n",
      "can't believe that happ\n",
      "Generating features\n",
      "can't believe that hap\n",
      "can't believe that ha\n",
      "can't believe that h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:49] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:49] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:49] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:49] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating featuresGenerating features\n",
      "\n",
      "Generating features\n",
      "         document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe happen         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "Generating featuresGenerating features\n",
      "\n",
      "      document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe hap         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "       document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe happ         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "        document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe happe         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "     document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe ha         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0      document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe h         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "\n",
      "can't believe that "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "can't believe thatcan't believe tha\n",
      "\n",
      "can't believe th\n",
      "Generating features\n",
      "can't believe t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't believe \n",
      "Generating features  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  believe         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "\n",
      "Generating features\n",
      "Generating features\n",
      "Generating features\n",
      "Generating features\n",
      "     document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe th         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "      document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  believe tha         2    0        0.0                     0   \n",
      "\n",
      "  has_top_love_word has_top_anger_word has_top_sadness_word has_top_fear_word  \\\n",
      "0                 0                  0                    0                 0   \n",
      "\n",
      "  has_top_joy_word  \n",
      "0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  believe         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  believe         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  believe         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "can't believe\n",
      "can't believ\n",
      "can't belie\n",
      "can't beli\n",
      "can't bel\n",
      "Generating features\n",
      "Generating features\n",
      "Generating featurescan't be\n",
      "Generating features\n",
      "\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0     beli         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  believe         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:50] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features\n",
      "\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0   believ         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    belie         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0      bel         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "can't can't b\n",
      "\n",
      "can'tcan'\n",
      "\n",
      "can\n",
      "Generating featuresGenerating features\n",
      "caGenerating features\n",
      "\n",
      "\n",
      "Generating features\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0    document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0        b         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0    document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:51] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:51] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:51] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:51] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:51] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:51] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0       ca         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "c\n",
      "\n",
      "Generating features\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0        c         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:51] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:51] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:52] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:52] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "so\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "so "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:52] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "so r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:52] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0        r         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:52] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so ro\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0       ro         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "so rom\n",
      "Generating features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:53] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:53] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0      rom         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "so roma\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0      rom         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:53] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:53] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so roman\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    roman         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "so romant\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0   romant         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:53] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:53] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so romanti\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  romanti         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "so romantic\n",
      "Generating features\n",
      "   document  n_tokens  n_i  sentiment has_top_surprise_word  \\\n",
      "0  romantic         1    0        0.0                     0   \n",
      "\n",
      "   has_top_love_word has_top_anger_word has_top_sadness_word  \\\n",
      "0                  1                  0                    0   \n",
      "\n",
      "  has_top_fear_word has_top_joy_word  \n",
      "0                 0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:54] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so romanti\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  romanti         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "so romant\n",
      "so roman\n",
      "so roma\n",
      "Generating featuresso rom\n",
      "\n",
      "so roGenerating features\n",
      "so r\n",
      "\n",
      "Generating features"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:55] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:55] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:55] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:55] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:55] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:55] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0   romant         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  Generating features\n",
      "\n",
      "Generating features\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    roman         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0      rom         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0    document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0      rom         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0        r         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0       ro         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "so \n",
      "so\n",
      "sGenerating features\n",
      "\n",
      "\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "Generating features\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0                  0    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:55] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:55] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:55] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 15:38:55] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:59] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0        f         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "fr"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:59] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:38:59] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0       fr         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "fra\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0      fra         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:39:00] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraz\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0     fraz         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "frazz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:39:00] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0    frazz         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:39:01] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frazzl\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0   frazzl         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n",
      "frazzle\n",
      "frazzled\n",
      "Generating features\n",
      "  document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  frazzle         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:39:01] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "127.0.0.1 - - [26/May/2022 15:39:01] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features\n",
      "   document  n_tokens  n_i  sentiment has_top_surprise_word has_top_love_word  \\\n",
      "0  frazzled         1    0        0.0                     0                 0   \n",
      "\n",
      "  has_top_anger_word has_top_sadness_word has_top_fear_word has_top_joy_word  \n",
      "0                  0                    0                 0                0  \n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
